---
title: "Unlocking Middle Earth"
subtitle: "A RAG-based tool for exploring *The Lord of the Rings*"
author: "Brent Benson"
date: "2024-06-19"
categories: [technology, ai, books]
image: "lotr_q_and_a.png"
---

Readers of J.R.R. Tolkien's books and watchers of the movie
adaptations develop varying levels of understanding of the complex
characters, geography, and lore of Middle Earth. Some dive in, head
first, poring over the driest sections of *The Silmarillion* and other
related texts and writings, while others enjoy the stories in a more
transactional context, understanding only what is needed to follow the
story.

Discussion with a well-versed Tolkien expert or reading along with
others in a book club can be an avenue towards deeper understanding
and enjoyment of a piece of literature, but we don't always have
someone around that fits the bill as a discussion partner.

My son has recently started delving into *The Lord of the Rings* again
and it gave me the idea of using Generative AI as a tool for enhancing
the Tolkien experience.

![An example of a question and answer from the RAG-based chatbot.](lotr_q_and_a.png)

## Retrieval-Augmented Generation

I am a big fan of using Retrieval-Augmented Generation or RAG as a way
of using Large Language Models to interact, summarize, and answer
questions about a set of texts. In my work in technology and learning
at Harvard Business School we have been indexing the textual elements
of our active, social, case-based online business courses to create
course assistant chatbots and interactive teaching elements.

The basic gist of RAG is to divide up the source text into a set of
chunks that are then indexed using vector embeddings, creating a
numeric vector for each textual chunk that represents (at some level)
the semantics of the text. The chunks and associated This database can
then be used to find a set of documents related to a query or
conversation that can be passed as context to a Large Language Model
(LLM) to synthesize an answer.

The advantage of using RAG compared to using an LLM like ChatGPT
without RAG, is that it focuses the conversation directly on the text,
minimizes bias and hallucinations, and also provides the ability to
show direct references and links to the textual chunks used to create
the LLM response. The current architecture of LLMs does not allow them
to provide direct references to source materials.

## Indexing the text of *The Lord of the Rings*

